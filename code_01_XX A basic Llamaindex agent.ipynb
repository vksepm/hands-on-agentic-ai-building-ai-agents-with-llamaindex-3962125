{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vksepm/hands-on-agentic-ai-building-ai-agents-with-llamaindex-3962125/blob/main/code_01_XX%20A%20basic%20Llamaindex%20agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c245bc-f356-4a22-abf5-fbfb99c084d5",
      "metadata": {
        "id": "e5c245bc-f356-4a22-abf5-fbfb99c084d5"
      },
      "source": [
        "### Install pre-requisite packages for the course\n",
        "\n",
        "Please ensure that this cell is run, to install all pre-requisite packages needed for subsequent code examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d734af97-9dea-44cf-a8cc-16717314cab0",
      "metadata": {
        "id": "d734af97-9dea-44cf-a8cc-16717314cab0",
        "outputId": "146836c2-0e14-4e8c-ba09-806b98ee4dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU python-dotenv\n",
        "!pip install -qU llama-index\n",
        "!pip install -qU llama-index-llms-openai\n",
        "!pip install -qU llama-index-embeddings-openai\n",
        "!pip install -qU llama-index-llms-azure-openai\n",
        "!pip install -qU llama-index-embeddings-azure-openai\n",
        "!pip install -qU llama-index-agent-introspective\n",
        "!pip install -qU llama-index-program-openai\n",
        "!pip install -qU llama-index-readers-file\n",
        "!pip install -qU pydantic\n",
        "!pip install -qU llama-index-core\n",
        "!pip install -qU llama-index-utils-workflow\n",
        "!pip install -qU llama-index-tools-wikipedia\n",
        "!pip install -qU llama-index-readers-json\n",
        "!pip install -qU llama-index-readers-file\n",
        "!pip install -qU pymupdf\n",
        "!pip install -qU llama-index-tools-google\n",
        "!pip install -qU nbformat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc3ce86-525e-4cdc-8045-2a06e0c05ec2",
      "metadata": {
        "id": "5dc3ce86-525e-4cdc-8045-2a06e0c05ec2"
      },
      "source": [
        "### 01.04. Setup LLM and Tools in LlamaIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d6b04af-403c-45e8-ad68-99ae72923828",
      "metadata": {
        "id": "8d6b04af-403c-45e8-ad68-99ae72923828"
      },
      "source": [
        "#### Setup the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92e10aa9-bb55-4dab-a440-c1ec0c8101ca",
      "metadata": {
        "id": "92e10aa9-bb55-4dab-a440-c1ec0c8101ca"
      },
      "outputs": [],
      "source": [
        "#Using AzureOpenAI as LLM. Other LLM options are available in LlamaIndex\n",
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.core import Settings\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "#Used by LlamaIndex\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#Setup the environment variables\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get('AZURE_OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_VERSION\"] = userdata.get('OPENAI_API_VERSION')\n",
        "\n",
        "#Note : Function calling support only available in GPT-4+\n",
        "#Create the LLM object\n",
        "llm=AzureOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    deployment_name=\"gpt-4o-mini\",\n",
        "    api_version=\"2024-08-01-preview\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55dc147e-bf55-4a24-a60e-e23bd7fe81c9",
      "metadata": {
        "id": "55dc147e-bf55-4a24-a60e-e23bd7fe81c9"
      },
      "source": [
        "#### Set up Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "63ebd9f1-faca-4416-850c-0ef3a432d87c",
      "metadata": {
        "id": "63ebd9f1-faca-4416-850c-0ef3a432d87c"
      },
      "outputs": [],
      "source": [
        "#define a couple of functions\n",
        "def find_sum(x:int, y:int) -> int :\n",
        "    #The docstring comment describes the capabilities of the function\n",
        "    #It is used by the agent to discover the function's inputs, outputs and capabilities\n",
        "    \"\"\"\n",
        "    This function is used to add two numbers and return their sum.\n",
        "    It takes two integers as inputs and returns an integer as output.\n",
        "    \"\"\"\n",
        "    return x + y\n",
        "\n",
        "def find_product(x:int, y:int) -> int :\n",
        "    \"\"\"\n",
        "    This function is used to multiply two numbers and return their product.\n",
        "    It takes two integers as inputs and returns an integer as ouput.\n",
        "    \"\"\"\n",
        "    return x * y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "386b164c-0577-447f-b491-d492ed25836c",
      "metadata": {
        "id": "386b164c-0577-447f-b491-d492ed25836c"
      },
      "source": [
        "### 01.05. Setup and execute an AI Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "903b48b3-861a-4805-b63b-e59956d34ba9",
      "metadata": {
        "id": "903b48b3-861a-4805-b63b-e59956d34ba9"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.agent.react.base import ReActAgent\n",
        "\n",
        "#Create function tools\n",
        "sum_tool = FunctionTool.from_defaults(find_sum)\n",
        "product_tool=FunctionTool.from_defaults(find_product)\n",
        "\n",
        "#Create a pre-built ReAct agent\n",
        "simple_agent = ReActAgent.from_tools(\n",
        "                [sum_tool, product_tool],\n",
        "                llm=llm,\n",
        "                verbose=True #Set verbose for detailed logs\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e11a416-c56a-4400-8f80-dae079117c58",
      "metadata": {
        "id": "7e11a416-c56a-4400-8f80-dae079117c58"
      },
      "source": [
        "#### Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a1dc1aa-3b80-41d1-bd69-d4c0cc7b57b8",
      "metadata": {
        "id": "4a1dc1aa-3b80-41d1-bd69-d4c0cc7b57b8",
        "outputId": "fb71402b-6d6d-42f9-d557-f5337f6f06ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 1c77c6aa-ad10-4915-9d0a-2c819fa9f1ff. Step input: What is 2 + 2? \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: find_sum\n",
            "Action Input: {'x': 2, 'y': 2}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 4\n",
            "\u001b[0m> Running step 0e2e2773-b857-4c2d-81a9-5f241c6cb6e7. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: 2 + 2 equals 4.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "response = simple_agent.chat(\"What is 2 + 2? \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "780a1810-416d-457b-9cc9-76320e46a0fd",
      "metadata": {
        "id": "780a1810-416d-457b-9cc9-76320e46a0fd",
        "outputId": "179e2b8e-de2d-4bb4-9b5e-d023dd2006d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step dbba45f4-9864-4073-bfb2-e5019a5babcc. Step input: Multiple 2 by 3 and then add 4\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: find_product\n",
            "Action Input: {'x': 2, 'y': 3}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 6\n",
            "\u001b[0m> Running step 460ac055-889c-40c4-9588-507f8a0a80b5. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Now that I have the product of 2 and 3, which is 6, I need to add 4 to it.\n",
            "Action: find_sum\n",
            "Action Input: {'x': 6, 'y': 4}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 10\n",
            "\u001b[0m> Running step 1514cedf-e4f8-4a9f-bcb9-4dffb94a3ee8. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: The result of multiplying 2 by 3 and then adding 4 is 10.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "response = simple_agent.chat(\"Multiple 2 by 3 and then add 4\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}